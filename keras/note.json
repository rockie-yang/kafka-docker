{
  "paragraphs": [
    {
      "text": "import numpy as np\nfrom keras import models, layers, optimizers, losses, metrics",
      "dateUpdated": "Mar 26, 2018 8:50:47 AM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1522054247421_-452356417",
      "id": "20180326-082253_284029627",
      "dateCreated": "Mar 26, 2018 8:50:47 AM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "from keras.datasets import imdb\n(train_data, train_label), (test_data, test_label) \u003d imdb.load_data(num_words\u003d10000)",
      "dateUpdated": "Mar 26, 2018 8:50:47 AM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\nUsing TensorFlow backend.\nDownloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n\n   16384/17464789 [..............................] - ETA: 0s\n   40960/17464789 [..............................] - ETA: 1:00\n   73728/17464789 [..............................] - ETA: 1:05\n  106496/17464789 [..............................] - ETA: 1:08\n  180224/17464789 [..............................] - ETA: 1:08\n  303104/17464789 [..............................] - ETA: 48s \n  442368/17464789 [..............................] - ETA: 38s\n  663552/17464789 [\u003e.............................] - ETA: 28s\n  892928/17464789 [\u003e.............................] - ETA: 22s\n  942080/17464789 [\u003e.............................] - ETA: 22s\n 1048576/17464789 [\u003e.............................] - ETA: 20s\n 1236992/17464789 [\u003d\u003e............................] - ETA: 18s\n 1294336/17464789 [\u003d\u003e............................] - ETA: 18s\n 1531904/17464789 [\u003d\u003e............................] - ETA: 15s\n 1622016/17464789 [\u003d\u003e............................] - ETA: 15s\n 1761280/17464789 [\u003d\u003d\u003e...........................] - ETA: 14s\n 2007040/17464789 [\u003d\u003d\u003e...........................] - ETA: 13s\n 2113536/17464789 [\u003d\u003d\u003e...........................] - ETA: 12s\n 2326528/17464789 [\u003d\u003d\u003e...........................] - ETA: 11s\n 2531328/17464789 [\u003d\u003d\u003d\u003e..........................] - ETA: 10s\n 2670592/17464789 [\u003d\u003d\u003d\u003e..........................] - ETA: 10s\n 2981888/17464789 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 9s \n 3104768/17464789 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 9s\n 3276800/17464789 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 9s\n 3727360/17464789 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 8s\n 3915776/17464789 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 7s\n 4423680/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 6s\n 4636672/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 6s\n 5046272/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 6s\n 5275648/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 5s\n 5537792/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 5s\n 5914624/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 5s\n 6012928/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 5s\n 6684672/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 4s\n 7012352/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 4s\n 7438336/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 3s\n 8060928/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 3s\n 8273920/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e................] - ETA: 3s\n 8896512/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 2s\n 9093120/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 2s\n 9338880/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 2s\n 9895936/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 2s\n10190848/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 2s\n10518528/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 2s\n11124736/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 1s\n11304960/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 1s\n11681792/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 1s\n12271616/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 1s\n12500992/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 1s\n13008896/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 1s\n13385728/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 1s\n13631488/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 1s\n14155776/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s\n14483456/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s\n14712832/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 0s\n15220736/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 0s\n15564800/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 0s\n15712256/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 0s\n15908864/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s\n16171008/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s\n16252928/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s\n16646144/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 0s\n17039360/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s\n17301504/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s\n17465344/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 4s 0us/step\n\n17473536/17464789 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 4s 0us/step\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1522054247426_-760540286",
      "id": "20180326-081404_1650011669",
      "dateCreated": "Mar 26, 2018 8:50:47 AM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "word_index \u003d imdb.get_word_index()\nreverse_word_index \u003d dict([(value, key) for (key, value) in word_index.items()])",
      "dateUpdated": "Mar 26, 2018 8:50:47 AM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n\n  16384/1641221 [..............................] - ETA: 0s\n  24576/1641221 [..............................] - ETA: 6s\n  57344/1641221 [\u003e.............................] - ETA: 6s\n 122880/1641221 [\u003d\u003e............................] - ETA: 5s\n 212992/1641221 [\u003d\u003d\u003e...........................] - ETA: 3s\n 262144/1641221 [\u003d\u003d\u003d\u003e..........................] - ETA: 2s\n 368640/1641221 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 2s\n 417792/1641221 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 2s\n 598016/1641221 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 1s\n 647168/1641221 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 1s\n 860160/1641221 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 0s\n 909312/1641221 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 0s\n1138688/1641221 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 0s\n1204224/1641221 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 0s\n1417216/1641221 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 0s\n1482752/1641221 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s\n1646592/1641221 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 1us/step\n\n1654784/1641221 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 1us/step\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1522054247427_-760925035",
      "id": "20180326-082128_1338026083",
      "dateCreated": "Mar 26, 2018 8:50:47 AM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "decoded_view \u003d \u0027 \u0027.join([reverse_word_index.get(i) for i in train_data[0]])\ndecoded_view",
      "dateUpdated": "Mar 26, 2018 8:50:47 AM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "u\"the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn\u0027t one will very to as itself with other and in of seen over landed for anyone of and br show\u0027s to whether from than out themselves history he name half some br of and odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn\u0027t to with armed acting watch an for with heartfelt film want an\"\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1522054247428_-762848779",
      "id": "20180326-082211_198186254",
      "dateCreated": "Mar 26, 2018 8:50:47 AM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "\ndef vectorized_sequences(sequences, dimensions\u003d10000):\n    result \u003d np.zeros((len(sequences), dimensions))\n    for i, sequence in enumerate(sequences):\n        result[i, sequence] \u003d 1\n    return result\n\nx_train \u003d vectorized_sequences(train_data)\nx_test  \u003d vectorized_sequences(test_data) \n\ny_train \u003d np.asarray(train_label).astype(\"float32\")\ny_test  \u003d np.asarray(test_label).astype(\"float32\")",
      "dateUpdated": "Mar 26, 2018 8:50:47 AM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1522054247428_-762848779",
      "id": "20180326-082231_576246165",
      "dateCreated": "Mar 26, 2018 8:50:47 AM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "model \u003d models.Sequential()\nmodel.add(layers.Dense(16, activation\u003d\"relu\", input_shape\u003dx_train[0].shape))\nmodel.add(layers.Dense(16, activation\u003d\"relu\"))\nmodel.add(layers.Dense(1, activation\u003d\"sigmoid\"))\nmodel.compile(optimizer\u003doptimizers.RMSprop(lr\u003d0.001), \n              loss\u003dlosses.binary_crossentropy, \n              metrics\u003d[metrics.binary_accuracy])",
      "dateUpdated": "Mar 26, 2018 8:50:47 AM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1522054247429_-763233528",
      "id": "20180326-082243_547724814",
      "dateCreated": "Mar 26, 2018 8:50:47 AM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val_size \u003d 10000\nx_val \u003d x_train[:val_size]\npartial_x_train \u003d x_train[val_size:]\ny_val \u003d y_train[:val_size]\npartial_y_train \u003d y_train[val_size:]\n",
      "dateUpdated": "Mar 26, 2018 8:50:47 AM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1522054247429_-763233528",
      "id": "20180326-082322_1788683220",
      "dateCreated": "Mar 26, 2018 8:50:47 AM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "history \u003d model.fit(partial_x_train, partial_y_train, epochs\u003d20, batch_size\u003d512, validation_data\u003d(x_val, y_val))",
      "dateUpdated": "Mar 26, 2018 8:50:47 AM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Train on 15000 samples, validate on 10000 samples\nEpoch 1/20\n\n2018-03-26 08:23:43.679900: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n\n  512/15000 [\u003e.............................] - ETA: 6s - loss: 0.6939 - binary_accuracy: 0.5020\n 1024/15000 [\u003d\u003e............................] - ETA: 4s - loss: 0.6918 - binary_accuracy: 0.5322\n 1536/15000 [\u003d\u003d\u003e...........................] - ETA: 3s - loss: 0.6848 - binary_accuracy: 0.5482\n 2048/15000 [\u003d\u003d\u003d\u003e..........................] - ETA: 2s - loss: 0.6751 - binary_accuracy: 0.5967\n 2560/15000 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 2s - loss: 0.6629 - binary_accuracy: 0.6223\n 3072/15000 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 2s - loss: 0.6532 - binary_accuracy: 0.6452\n 3584/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 1s - loss: 0.6476 - binary_accuracy: 0.6406\n 4096/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 1s - loss: 0.6424 - binary_accuracy: 0.6421\n 4608/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 1s - loss: 0.6315 - binary_accuracy: 0.6589\n 5120/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 1s - loss: 0.6225 - binary_accuracy: 0.6746\n 5632/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 1s - loss: 0.6151 - binary_accuracy: 0.6824\n 6144/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 1s - loss: 0.6062 - binary_accuracy: 0.6943\n 6656/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 1s - loss: 0.5992 - binary_accuracy: 0.7027\n 7168/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e................] - ETA: 1s - loss: 0.5914 - binary_accuracy: 0.7112\n 7680/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 0s - loss: 0.5817 - binary_accuracy: 0.7211\n 8192/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 0s - loss: 0.5756 - binary_accuracy: 0.7273\n 8704/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 0s - loss: 0.5698 - binary_accuracy: 0.7331\n 9216/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 0s - loss: 0.5651 - binary_accuracy: 0.7380\n 9728/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 0s - loss: 0.5609 - binary_accuracy: 0.7411\n10240/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 0s - loss: 0.5553 - binary_accuracy: 0.7464\n10752/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 0s - loss: 0.5505 - binary_accuracy: 0.7498\n11264/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 0s - loss: 0.5447 - binary_accuracy: 0.7551\n11776/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 0s - loss: 0.5392 - binary_accuracy: 0.7590\n12288/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s - loss: 0.5343 - binary_accuracy: 0.7633\n12800/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 0s - loss: 0.5284 - binary_accuracy: 0.7673\n13312/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 0s - loss: 0.5234 - binary_accuracy: 0.7707\n13824/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s - loss: 0.5190 - binary_accuracy: 0.7739\n14336/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 0s - loss: 0.5145 - binary_accuracy: 0.7771\n14848/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s - loss: 0.5100 - binary_accuracy: 0.7803\n15000/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 3s 172us/step - loss: 0.5085 - binary_accuracy: 0.7815 - val_loss: 0.3797 - val_binary_accuracy: 0.8684\nEpoch 2/20\n\n  512/15000 [\u003e.............................] - ETA: 1s - loss: 0.3237 - binary_accuracy: 0.9062\n 1536/15000 [\u003d\u003d\u003e...........................] - ETA: 1s - loss: 0.3321 - binary_accuracy: 0.9102\n 2560/15000 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 1s - loss: 0.3230 - binary_accuracy: 0.9102\n 3072/15000 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 1s - loss: 0.3201 - binary_accuracy: 0.9115\n 3584/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 1s - loss: 0.3176 - binary_accuracy: 0.9138\n 4608/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 0s - loss: 0.3119 - binary_accuracy: 0.9130\n 5120/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 0s - loss: 0.3080 - binary_accuracy: 0.9156\n 5632/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 0s - loss: 0.3090 - binary_accuracy: 0.9135\n 6144/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 0s - loss: 0.3045 - binary_accuracy: 0.9136\n 7168/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e................] - ETA: 0s - loss: 0.3096 - binary_accuracy: 0.9075\n 8192/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 0s - loss: 0.3114 - binary_accuracy: 0.9045\n 9216/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 0s - loss: 0.3107 - binary_accuracy: 0.9044\n 9728/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 0s - loss: 0.3098 - binary_accuracy: 0.9044\n10240/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 0s - loss: 0.3084 - binary_accuracy: 0.9054\n11264/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 0s - loss: 0.3085 - binary_accuracy: 0.9046\n12288/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s - loss: 0.3061 - binary_accuracy: 0.9041\n13312/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 0s - loss: 0.3037 - binary_accuracy: 0.9044\n14336/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 0s - loss: 0.3022 - binary_accuracy: 0.9041\n15000/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s 134us/step - loss: 0.3005 - binary_accuracy: 0.9045 - val_loss: 0.3002 - val_binary_accuracy: 0.8899\nEpoch 3/20\n\n  512/15000 [\u003e.............................] - ETA: 1s - loss: 0.2118 - binary_accuracy: 0.9375\n 1536/15000 [\u003d\u003d\u003e...........................] - ETA: 1s - loss: 0.2228 - binary_accuracy: 0.9323\n 2560/15000 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 1s - loss: 0.2193 - binary_accuracy: 0.9363\n 3584/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 0s - loss: 0.2250 - binary_accuracy: 0.9302\n 4608/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 0s - loss: 0.2216 - binary_accuracy: 0.9329\n 5632/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 0s - loss: 0.2232 - binary_accuracy: 0.9318\n 6656/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 0s - loss: 0.2208 - binary_accuracy: 0.9319\n 7680/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 0s - loss: 0.2227 - binary_accuracy: 0.9302\n 8704/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 0s - loss: 0.2232 - binary_accuracy: 0.9277\n 9728/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 0s - loss: 0.2221 - binary_accuracy: 0.9281\n10752/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 0s - loss: 0.2205 - binary_accuracy: 0.9282\n11776/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 0s - loss: 0.2203 - binary_accuracy: 0.9280\n12800/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 0s - loss: 0.2200 - binary_accuracy: 0.9277\n13824/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s - loss: 0.2182 - binary_accuracy: 0.9285\n14848/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s - loss: 0.2181 - binary_accuracy: 0.9288\n15000/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s 130us/step - loss: 0.2180 - binary_accuracy: 0.9286 - val_loss: 0.3085 - val_binary_accuracy: 0.8713\nEpoch 4/20\n\n  512/15000 [\u003e.............................] - ETA: 1s - loss: 0.1953 - binary_accuracy: 0.9375\n 1536/15000 [\u003d\u003d\u003e...........................] - ETA: 1s - loss: 0.1897 - binary_accuracy: 0.9375\n 2048/15000 [\u003d\u003d\u003d\u003e..........................] - ETA: 1s - loss: 0.1858 - binary_accuracy: 0.9429\n 2560/15000 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 1s - loss: 0.1855 - binary_accuracy: 0.9418\n 3072/15000 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 1s - loss: 0.1823 - binary_accuracy: 0.9443\n 3584/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 1s - loss: 0.1766 - binary_accuracy: 0.9478\n 4096/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 1s - loss: 0.1778 - binary_accuracy: 0.9473\n 4608/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 1s - loss: 0.1758 - binary_accuracy: 0.9490\n 5120/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 0s - loss: 0.1763 - binary_accuracy: 0.9488\n 5632/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 0s - loss: 0.1771 - binary_accuracy: 0.9473\n 6144/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 0s - loss: 0.1768 - binary_accuracy: 0.9466\n 6656/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 0s - loss: 0.1752 - binary_accuracy: 0.9476\n 7168/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e................] - ETA: 0s - loss: 0.1749 - binary_accuracy: 0.9473\n 7680/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 0s - loss: 0.1741 - binary_accuracy: 0.9486\n 8192/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 0s - loss: 0.1732 - binary_accuracy: 0.9487\n 8704/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 0s - loss: 0.1727 - binary_accuracy: 0.9482\n 9216/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 0s - loss: 0.1723 - binary_accuracy: 0.9482\n10240/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 0s - loss: 0.1724 - binary_accuracy: 0.9481\n10752/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 0s - loss: 0.1737 - binary_accuracy: 0.9467\n11264/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 0s - loss: 0.1747 - binary_accuracy: 0.9455\n11776/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 0s - loss: 0.1750 - binary_accuracy: 0.9448\n12288/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s - loss: 0.1766 - binary_accuracy: 0.9441\n12800/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 0s - loss: 0.1771 - binary_accuracy: 0.9432\n13312/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 0s - loss: 0.1772 - binary_accuracy: 0.9430\n13824/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s - loss: 0.1764 - binary_accuracy: 0.9434\n14336/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 0s - loss: 0.1762 - binary_accuracy: 0.9436\n14848/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s - loss: 0.1754 - binary_accuracy: 0.9436\n15000/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s 145us/step - loss: 0.1751 - binary_accuracy: 0.9436 - val_loss: 0.2839 - val_binary_accuracy: 0.8831\nEpoch 5/20\n\n  512/15000 [\u003e.............................] - ETA: 1s - loss: 0.1320 - binary_accuracy: 0.9688\n 1536/15000 [\u003d\u003d\u003e...........................] - ETA: 1s - loss: 0.1438 - binary_accuracy: 0.9616\n 2560/15000 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 1s - loss: 0.1379 - binary_accuracy: 0.9633\n 3072/15000 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 1s - loss: 0.1386 - binary_accuracy: 0.9639\n 3584/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 1s - loss: 0.1358 - binary_accuracy: 0.9651\n 4608/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 0s - loss: 0.1356 - binary_accuracy: 0.9644\n 5632/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 0s - loss: 0.1373 - binary_accuracy: 0.9631\n 6656/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 0s - loss: 0.1416 - binary_accuracy: 0.9593\n 7168/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e................] - ETA: 0s - loss: 0.1411 - binary_accuracy: 0.9590\n 7680/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 0s - loss: 0.1414 - binary_accuracy: 0.9586\n 8192/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 0s - loss: 0.1402 - binary_accuracy: 0.9583\n 9216/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 0s - loss: 0.1393 - binary_accuracy: 0.9588\n10240/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 0s - loss: 0.1394 - binary_accuracy: 0.9581\n10752/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 0s - loss: 0.1407 - binary_accuracy: 0.9570\n11776/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 0s - loss: 0.1412 - binary_accuracy: 0.9564\n12800/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 0s - loss: 0.1413 - binary_accuracy: 0.9555\n13824/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s - loss: 0.1429 - binary_accuracy: 0.9544\n14336/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 0s - loss: 0.1429 - binary_accuracy: 0.9541\n14848/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s - loss: 0.1425 - binary_accuracy: 0.9542\n15000/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s 139us/step - loss: 0.1427 - binary_accuracy: 0.9543 - val_loss: 0.2847 - val_binary_accuracy: 0.8865\nEpoch 6/20\n\n  512/15000 [\u003e.............................] - ETA: 1s - loss: 0.1235 - binary_accuracy: 0.9668\n 1536/15000 [\u003d\u003d\u003e...........................] - ETA: 1s - loss: 0.1156 - binary_accuracy: 0.9688\n 2560/15000 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 1s - loss: 0.1055 - binary_accuracy: 0.9723\n 3584/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 1s - loss: 0.1070 - binary_accuracy: 0.9713\n 4096/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 0s - loss: 0.1080 - binary_accuracy: 0.9714\n 4608/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 0s - loss: 0.1126 - binary_accuracy: 0.9696\n 5120/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 0s - loss: 0.1169 - binary_accuracy: 0.9672\n 6144/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 0s - loss: 0.1146 - binary_accuracy: 0.9676\n 7168/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e................] - ETA: 0s - loss: 0.1161 - binary_accuracy: 0.9669\n 7680/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 0s - loss: 0.1164 - binary_accuracy: 0.9661\n 8704/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 0s - loss: 0.1162 - binary_accuracy: 0.9653\n 9728/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 0s - loss: 0.1155 - binary_accuracy: 0.9653\n10752/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 0s - loss: 0.1153 - binary_accuracy: 0.9650\n11264/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 0s - loss: 0.1147 - binary_accuracy: 0.9649\n11776/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 0s - loss: 0.1146 - binary_accuracy: 0.9650\n12800/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 0s - loss: 0.1149 - binary_accuracy: 0.9650\n13824/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s - loss: 0.1154 - binary_accuracy: 0.9648\n14848/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s - loss: 0.1149 - binary_accuracy: 0.9652\n15000/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s 133us/step - loss: 0.1150 - binary_accuracy: 0.9653 - val_loss: 0.3149 - val_binary_accuracy: 0.8772\nEpoch 7/20\n\n  512/15000 [\u003e.............................] - ETA: 1s - loss: 0.1016 - binary_accuracy: 0.9707\n 1536/15000 [\u003d\u003d\u003e...........................] - ETA: 1s - loss: 0.1000 - binary_accuracy: 0.9701\n 2560/15000 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 1s - loss: 0.0955 - binary_accuracy: 0.9746\n 3072/15000 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 1s - loss: 0.0973 - binary_accuracy: 0.9733\n 3584/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 1s - loss: 0.0939 - binary_accuracy: 0.9746\n 4608/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 0s - loss: 0.0913 - binary_accuracy: 0.9753\n 5120/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 0s - loss: 0.0910 - binary_accuracy: 0.9756\n 5632/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 0s - loss: 0.0902 - binary_accuracy: 0.9760\n 6144/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 0s - loss: 0.0918 - binary_accuracy: 0.9749\n 6656/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 0s - loss: 0.0918 - binary_accuracy: 0.9748\n 7168/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e................] - ETA: 0s - loss: 0.0943 - binary_accuracy: 0.9734\n 7680/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 0s - loss: 0.0942 - binary_accuracy: 0.9736\n 8704/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 0s - loss: 0.0956 - binary_accuracy: 0.9724\n 9216/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 0s - loss: 0.0959 - binary_accuracy: 0.9723\n10240/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 0s - loss: 0.0971 - binary_accuracy: 0.9721\n11264/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 0s - loss: 0.0981 - binary_accuracy: 0.9709\n11776/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 0s - loss: 0.0973 - binary_accuracy: 0.9713\n12800/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 0s - loss: 0.0972 - binary_accuracy: 0.9712\n13312/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 0s - loss: 0.0973 - binary_accuracy: 0.9715\n13824/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s - loss: 0.0979 - binary_accuracy: 0.9707\n14336/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 0s - loss: 0.0977 - binary_accuracy: 0.9708\n15000/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s 138us/step - loss: 0.0979 - binary_accuracy: 0.9708 - val_loss: 0.3127 - val_binary_accuracy: 0.8846\nEpoch 8/20\n\n  512/15000 [\u003e.............................] - ETA: 1s - loss: 0.0728 - binary_accuracy: 0.9844\n 1536/15000 [\u003d\u003d\u003e...........................] - ETA: 1s - loss: 0.0710 - binary_accuracy: 0.9818\n 2560/15000 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 1s - loss: 0.0690 - binary_accuracy: 0.9836\n 3584/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 1s - loss: 0.0729 - binary_accuracy: 0.9802\n 4096/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 1s - loss: 0.0737 - binary_accuracy: 0.9802\n 5120/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 0s - loss: 0.0762 - binary_accuracy: 0.9779\n 6144/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 0s - loss: 0.0755 - binary_accuracy: 0.9790\n 6656/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 0s - loss: 0.0752 - binary_accuracy: 0.9785\n 7680/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 0s - loss: 0.0747 - binary_accuracy: 0.9789\n 8704/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 0s - loss: 0.0758 - binary_accuracy: 0.9785\n 9728/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 0s - loss: 0.0786 - binary_accuracy: 0.9771\n10752/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 0s - loss: 0.0804 - binary_accuracy: 0.9765\n11776/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 0s - loss: 0.0797 - binary_accuracy: 0.9768\n12800/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 0s - loss: 0.0797 - binary_accuracy: 0.9766\n13824/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s - loss: 0.0790 - binary_accuracy: 0.9771\n14336/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 0s - loss: 0.0794 - binary_accuracy: 0.9771\n14848/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s - loss: 0.0797 - binary_accuracy: 0.9768\n15000/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s 137us/step - loss: 0.0807 - binary_accuracy: 0.9763 - val_loss: 0.3859 - val_binary_accuracy: 0.8652\nEpoch 9/20\n\n  512/15000 [\u003e.............................] - ETA: 1s - loss: 0.0832 - binary_accuracy: 0.9746\n 1536/15000 [\u003d\u003d\u003e...........................] - ETA: 1s - loss: 0.0653 - binary_accuracy: 0.9831\n 2560/15000 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 1s - loss: 0.0594 - binary_accuracy: 0.9871\n 3584/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 1s - loss: 0.0588 - binary_accuracy: 0.9877\n 4096/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 1s - loss: 0.0591 - binary_accuracy: 0.9878\n 4608/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 0s - loss: 0.0595 - binary_accuracy: 0.9874\n 5632/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 0s - loss: 0.0626 - binary_accuracy: 0.9856\n 6144/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 0s - loss: 0.0617 - binary_accuracy: 0.9858\n 6656/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 0s - loss: 0.0614 - binary_accuracy: 0.9859\n 7168/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e................] - ETA: 0s - loss: 0.0616 - binary_accuracy: 0.9858\n 7680/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 0s - loss: 0.0615 - binary_accuracy: 0.9857\n 8192/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 0s - loss: 0.0616 - binary_accuracy: 0.9856\n 9216/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 0s - loss: 0.0627 - binary_accuracy: 0.9850\n 9728/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 0s - loss: 0.0637 - binary_accuracy: 0.9842\n10240/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 0s - loss: 0.0653 - binary_accuracy: 0.9831\n10752/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 0s - loss: 0.0668 - binary_accuracy: 0.9824\n11776/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 0s - loss: 0.0670 - binary_accuracy: 0.9823\n12800/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 0s - loss: 0.0669 - binary_accuracy: 0.9824\n13312/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 0s - loss: 0.0666 - binary_accuracy: 0.9823\n13824/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s - loss: 0.0661 - binary_accuracy: 0.9823\n14336/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 0s - loss: 0.0659 - binary_accuracy: 0.9824\n14848/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s - loss: 0.0657 - binary_accuracy: 0.9824\n15000/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s 142us/step - loss: 0.0660 - binary_accuracy: 0.9821 - val_loss: 0.3634 - val_binary_accuracy: 0.8784\nEpoch 10/20\n\n  512/15000 [\u003e.............................] - ETA: 1s - loss: 0.0551 - binary_accuracy: 0.9922\n 1536/15000 [\u003d\u003d\u003e...........................] - ETA: 1s - loss: 0.0517 - binary_accuracy: 0.9915\n 2048/15000 [\u003d\u003d\u003d\u003e..........................] - ETA: 1s - loss: 0.0513 - binary_accuracy: 0.9907\n 2560/15000 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 1s - loss: 0.0517 - binary_accuracy: 0.9887\n 3072/15000 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 1s - loss: 0.0522 - binary_accuracy: 0.9889\n 3584/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 1s - loss: 0.0534 - binary_accuracy: 0.9883\n 4096/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 1s - loss: 0.0530 - binary_accuracy: 0.9885\n 5120/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 0s - loss: 0.0524 - binary_accuracy: 0.9883\n 5632/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 0s - loss: 0.0525 - binary_accuracy: 0.9881\n 6144/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 0s - loss: 0.0519 - binary_accuracy: 0.9884\n 6656/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 0s - loss: 0.0512 - binary_accuracy: 0.9890\n 7680/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 0s - loss: 0.0522 - binary_accuracy: 0.9889\n 8192/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 0s - loss: 0.0520 - binary_accuracy: 0.9886\n 8704/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 0s - loss: 0.0520 - binary_accuracy: 0.9885\n 9216/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 0s - loss: 0.0519 - binary_accuracy: 0.9885\n 9728/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 0s - loss: 0.0524 - binary_accuracy: 0.9882\n10240/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 0s - loss: 0.0534 - binary_accuracy: 0.9876\n11264/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 0s - loss: 0.0548 - binary_accuracy: 0.9868\n12288/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s - loss: 0.0565 - binary_accuracy: 0.9852\n13312/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 0s - loss: 0.0560 - binary_accuracy: 0.9853\n13824/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s - loss: 0.0555 - binary_accuracy: 0.9854\n14848/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s - loss: 0.0552 - binary_accuracy: 0.9855\n15000/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s 141us/step - loss: 0.0556 - binary_accuracy: 0.9851 - val_loss: 0.3843 - val_binary_accuracy: 0.8792\nEpoch 11/20\n\n  512/15000 [\u003e.............................] - ETA: 1s - loss: 0.0410 - binary_accuracy: 0.9922\n 1536/15000 [\u003d\u003d\u003e...........................] - ETA: 1s - loss: 0.0325 - binary_accuracy: 0.9967\n 2560/15000 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 1s - loss: 0.0364 - binary_accuracy: 0.9945\n 3584/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 1s - loss: 0.0353 - binary_accuracy: 0.9950\n 4096/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 1s - loss: 0.0345 - binary_accuracy: 0.9949\n 4608/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 1s - loss: 0.0341 - binary_accuracy: 0.9948\n 5632/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 0s - loss: 0.0358 - binary_accuracy: 0.9940\n 6656/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 0s - loss: 0.0356 - binary_accuracy: 0.9941\n 7680/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 0s - loss: 0.0363 - binary_accuracy: 0.9939\n 8192/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 0s - loss: 0.0376 - binary_accuracy: 0.9932\n 8704/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 0s - loss: 0.0419 - binary_accuracy: 0.9908\n 9216/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 0s - loss: 0.0438 - binary_accuracy: 0.9896\n 9728/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 0s - loss: 0.0443 - binary_accuracy: 0.9894\n10752/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 0s - loss: 0.0441 - binary_accuracy: 0.9894\n11776/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 0s - loss: 0.0443 - binary_accuracy: 0.9890\n12800/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 0s - loss: 0.0445 - binary_accuracy: 0.9891\n13824/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s - loss: 0.0444 - binary_accuracy: 0.9893\n14848/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s - loss: 0.0451 - binary_accuracy: 0.9888\n15000/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s 137us/step - loss: 0.0450 - binary_accuracy: 0.9888 - val_loss: 0.4162 - val_binary_accuracy: 0.8773\nEpoch 12/20\n\n  512/15000 [\u003e.............................] - ETA: 1s - loss: 0.0296 - binary_accuracy: 0.9961\n 1536/15000 [\u003d\u003d\u003e...........................] - ETA: 1s - loss: 0.0279 - binary_accuracy: 0.9967\n 2560/15000 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 1s - loss: 0.0277 - binary_accuracy: 0.9973\n 3072/15000 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 1s - loss: 0.0278 - binary_accuracy: 0.9967\n 3584/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 1s - loss: 0.0277 - binary_accuracy: 0.9969\n 4608/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 0s - loss: 0.0285 - binary_accuracy: 0.9967\n 5632/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 0s - loss: 0.0319 - binary_accuracy: 0.9947\n 6656/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 0s - loss: 0.0324 - binary_accuracy: 0.9947\n 7680/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 0s - loss: 0.0318 - binary_accuracy: 0.9949\n 8704/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 0s - loss: 0.0316 - binary_accuracy: 0.9949\n 9728/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 0s - loss: 0.0323 - binary_accuracy: 0.9948\n10752/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 0s - loss: 0.0328 - binary_accuracy: 0.9946\n11264/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 0s - loss: 0.0326 - binary_accuracy: 0.9947\n12288/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s - loss: 0.0334 - binary_accuracy: 0.9941\n13312/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 0s - loss: 0.0354 - binary_accuracy: 0.9927\n14336/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 0s - loss: 0.0381 - binary_accuracy: 0.9914\n15000/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s 132us/step - loss: 0.0384 - binary_accuracy: 0.9913 - val_loss: 0.4506 - val_binary_accuracy: 0.8698\nEpoch 13/20\n\n  512/15000 [\u003e.............................] - ETA: 1s - loss: 0.0250 - binary_accuracy: 1.0000\n 1536/15000 [\u003d\u003d\u003e...........................] - ETA: 1s - loss: 0.0246 - binary_accuracy: 0.9980\n 2560/15000 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 1s - loss: 0.0273 - binary_accuracy: 0.9957\n 3584/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 1s - loss: 0.0256 - binary_accuracy: 0.9964\n 4608/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 0s - loss: 0.0246 - binary_accuracy: 0.9970\n 5632/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 0s - loss: 0.0237 - binary_accuracy: 0.9970\n 6144/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 0s - loss: 0.0240 - binary_accuracy: 0.9969\n 6656/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 0s - loss: 0.0241 - binary_accuracy: 0.9967\n 7680/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 0s - loss: 0.0252 - binary_accuracy: 0.9958\n 8704/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 0s - loss: 0.0248 - binary_accuracy: 0.9963\n 9728/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 0s - loss: 0.0249 - binary_accuracy: 0.9962\n10752/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 0s - loss: 0.0253 - binary_accuracy: 0.9961\n11264/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 0s - loss: 0.0262 - binary_accuracy: 0.9956\n11776/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 0s - loss: 0.0268 - binary_accuracy: 0.9951\n12288/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s - loss: 0.0281 - binary_accuracy: 0.9943\n12800/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 0s - loss: 0.0294 - binary_accuracy: 0.9935\n13312/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 0s - loss: 0.0299 - binary_accuracy: 0.9930\n14336/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 0s - loss: 0.0301 - binary_accuracy: 0.9927\n15000/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s 137us/step - loss: 0.0299 - binary_accuracy: 0.9929 - val_loss: 0.4698 - val_binary_accuracy: 0.8730\nEpoch 14/20\n\n  512/15000 [\u003e.............................] - ETA: 1s - loss: 0.0182 - binary_accuracy: 0.9980\n 1536/15000 [\u003d\u003d\u003e...........................] - ETA: 1s - loss: 0.0191 - binary_accuracy: 0.9974\n 2560/15000 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 1s - loss: 0.0181 - binary_accuracy: 0.9977\n 3072/15000 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 1s - loss: 0.0194 - binary_accuracy: 0.9971\n 3584/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 1s - loss: 0.0190 - binary_accuracy: 0.9972\n 4096/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 1s - loss: 0.0186 - binary_accuracy: 0.9976\n 4608/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 0s - loss: 0.0187 - binary_accuracy: 0.9972\n 5632/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 0s - loss: 0.0190 - binary_accuracy: 0.9972\n 6656/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 0s - loss: 0.0190 - binary_accuracy: 0.9973\n 7680/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 0s - loss: 0.0189 - binary_accuracy: 0.9974\n 8704/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 0s - loss: 0.0190 - binary_accuracy: 0.9974\n 9728/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 0s - loss: 0.0196 - binary_accuracy: 0.9969\n10240/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 0s - loss: 0.0216 - binary_accuracy: 0.9958\n11264/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 0s - loss: 0.0251 - binary_accuracy: 0.9941\n12288/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s - loss: 0.0249 - binary_accuracy: 0.9942\n13312/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 0s - loss: 0.0246 - binary_accuracy: 0.9945\n13824/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s - loss: 0.0246 - binary_accuracy: 0.9946\n14336/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 0s - loss: 0.0246 - binary_accuracy: 0.9948\n14848/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s - loss: 0.0245 - binary_accuracy: 0.9948\n15000/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s 139us/step - loss: 0.0244 - binary_accuracy: 0.9949 - val_loss: 0.5028 - val_binary_accuracy: 0.8718\nEpoch 15/20\n\n  512/15000 [\u003e.............................] - ETA: 1s - loss: 0.0102 - binary_accuracy: 1.0000\n 1536/15000 [\u003d\u003d\u003e...........................] - ETA: 1s - loss: 0.0144 - binary_accuracy: 0.9974\n 2048/15000 [\u003d\u003d\u003d\u003e..........................] - ETA: 1s - loss: 0.0142 - binary_accuracy: 0.9976\n 2560/15000 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 1s - loss: 0.0141 - binary_accuracy: 0.9977\n 3584/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 1s - loss: 0.0147 - binary_accuracy: 0.9983\n 4608/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 0s - loss: 0.0145 - binary_accuracy: 0.9985\n 5120/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 0s - loss: 0.0149 - binary_accuracy: 0.9986\n 5632/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 0s - loss: 0.0148 - binary_accuracy: 0.9988\n 6144/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 0s - loss: 0.0149 - binary_accuracy: 0.9985\n 6656/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 0s - loss: 0.0149 - binary_accuracy: 0.9986\n 7168/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e................] - ETA: 0s - loss: 0.0152 - binary_accuracy: 0.9986\n 7680/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 0s - loss: 0.0156 - binary_accuracy: 0.9983\n 8704/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 0s - loss: 0.0166 - binary_accuracy: 0.9982\n 9216/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 0s - loss: 0.0174 - binary_accuracy: 0.9978\n 9728/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 0s - loss: 0.0181 - binary_accuracy: 0.9977\n10240/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 0s - loss: 0.0180 - binary_accuracy: 0.9979\n11264/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 0s - loss: 0.0180 - binary_accuracy: 0.9979\n12288/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s - loss: 0.0180 - binary_accuracy: 0.9979\n12800/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 0s - loss: 0.0178 - binary_accuracy: 0.9980\n13312/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 0s - loss: 0.0176 - binary_accuracy: 0.9980\n13824/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s - loss: 0.0176 - binary_accuracy: 0.9979\n14336/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 0s - loss: 0.0177 - binary_accuracy: 0.9978\n15000/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s 140us/step - loss: 0.0176 - binary_accuracy: 0.9979 - val_loss: 0.5390 - val_binary_accuracy: 0.8682\nEpoch 16/20\n\n  512/15000 [\u003e.............................] - ETA: 1s - loss: 0.0177 - binary_accuracy: 0.9961\n 1536/15000 [\u003d\u003d\u003e...........................] - ETA: 1s - loss: 0.0136 - binary_accuracy: 0.9974\n 2560/15000 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 1s - loss: 0.0127 - binary_accuracy: 0.9980\n 3584/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 1s - loss: 0.0122 - binary_accuracy: 0.9986\n 4608/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 0s - loss: 0.0125 - binary_accuracy: 0.9987\n 5632/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 0s - loss: 0.0139 - binary_accuracy: 0.9982\n 6656/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 0s - loss: 0.0153 - binary_accuracy: 0.9980\n 7680/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 0s - loss: 0.0157 - binary_accuracy: 0.9975\n 8704/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 0s - loss: 0.0153 - binary_accuracy: 0.9977\n 9728/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 0s - loss: 0.0150 - binary_accuracy: 0.9978\n10240/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 0s - loss: 0.0150 - binary_accuracy: 0.9979\n10752/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 0s - loss: 0.0148 - binary_accuracy: 0.9979\n11264/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 0s - loss: 0.0148 - binary_accuracy: 0.9979\n11776/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 0s - loss: 0.0147 - binary_accuracy: 0.9978\n12800/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 0s - loss: 0.0145 - binary_accuracy: 0.9979\n13824/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s - loss: 0.0144 - binary_accuracy: 0.9980\n14336/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 0s - loss: 0.0150 - binary_accuracy: 0.9976\n14848/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s - loss: 0.0166 - binary_accuracy: 0.9969\n15000/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s 139us/step - loss: 0.0169 - binary_accuracy: 0.9967 - val_loss: 0.5731 - val_binary_accuracy: 0.8695\nEpoch 17/20\n\n  512/15000 [\u003e.............................] - ETA: 1s - loss: 0.0095 - binary_accuracy: 1.0000\n 1536/15000 [\u003d\u003d\u003e...........................] - ETA: 1s - loss: 0.0085 - binary_accuracy: 1.0000\n 2560/15000 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 1s - loss: 0.0081 - binary_accuracy: 1.0000\n 3584/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 1s - loss: 0.0081 - binary_accuracy: 1.0000\n 4608/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 0s - loss: 0.0081 - binary_accuracy: 0.9998\n 5632/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 0s - loss: 0.0084 - binary_accuracy: 0.9998\n 6656/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 0s - loss: 0.0082 - binary_accuracy: 0.9998\n 7680/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 0s - loss: 0.0082 - binary_accuracy: 0.9999\n 8192/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 0s - loss: 0.0086 - binary_accuracy: 0.9996\n 8704/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 0s - loss: 0.0086 - binary_accuracy: 0.9997\n 9728/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 0s - loss: 0.0086 - binary_accuracy: 0.9996\n10752/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 0s - loss: 0.0089 - binary_accuracy: 0.9994\n11264/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 0s - loss: 0.0089 - binary_accuracy: 0.9995\n11776/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 0s - loss: 0.0090 - binary_accuracy: 0.9995\n12800/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 0s - loss: 0.0092 - binary_accuracy: 0.9995\n13824/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s - loss: 0.0091 - binary_accuracy: 0.9996\n14848/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s - loss: 0.0093 - binary_accuracy: 0.9995\n15000/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s 139us/step - loss: 0.0093 - binary_accuracy: 0.9995 - val_loss: 0.6152 - val_binary_accuracy: 0.8656\nEpoch 18/20\n\n  512/15000 [\u003e.............................] - ETA: 1s - loss: 0.0079 - binary_accuracy: 1.0000\n 1536/15000 [\u003d\u003d\u003e...........................] - ETA: 1s - loss: 0.0063 - binary_accuracy: 1.0000\n 2048/15000 [\u003d\u003d\u003d\u003e..........................] - ETA: 1s - loss: 0.0064 - binary_accuracy: 1.0000\n 3072/15000 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 1s - loss: 0.0061 - binary_accuracy: 1.0000\n 3584/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 1s - loss: 0.0064 - binary_accuracy: 1.0000\n 4096/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 1s - loss: 0.0064 - binary_accuracy: 1.0000\n 4608/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 0s - loss: 0.0065 - binary_accuracy: 1.0000\n 5120/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 0s - loss: 0.0067 - binary_accuracy: 1.0000\n 5632/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 0s - loss: 0.0069 - binary_accuracy: 1.0000\n 6656/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 0s - loss: 0.0091 - binary_accuracy: 0.9991\n 7168/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e................] - ETA: 0s - loss: 0.0154 - binary_accuracy: 0.9955\n 7680/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 0s - loss: 0.0158 - binary_accuracy: 0.9954\n 8192/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 0s - loss: 0.0151 - binary_accuracy: 0.9957\n 8704/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 0s - loss: 0.0146 - binary_accuracy: 0.9960\n 9216/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 0s - loss: 0.0140 - binary_accuracy: 0.9962\n 9728/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 0s - loss: 0.0137 - binary_accuracy: 0.9964\n10240/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 0s - loss: 0.0134 - binary_accuracy: 0.9966\n10752/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 0s - loss: 0.0131 - binary_accuracy: 0.9967\n11264/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 0s - loss: 0.0128 - binary_accuracy: 0.9969\n11776/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 0s - loss: 0.0127 - binary_accuracy: 0.9969\n12288/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s - loss: 0.0123 - binary_accuracy: 0.9970\n12800/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 0s - loss: 0.0124 - binary_accuracy: 0.9970\n13824/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s - loss: 0.0121 - binary_accuracy: 0.9973\n14848/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s - loss: 0.0118 - binary_accuracy: 0.9974\n15000/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s 138us/step - loss: 0.0118 - binary_accuracy: 0.9974 - val_loss: 0.6387 - val_binary_accuracy: 0.8666\nEpoch 19/20\n\n  512/15000 [\u003e.............................] - ETA: 1s - loss: 0.0056 - binary_accuracy: 1.0000\n 1536/15000 [\u003d\u003d\u003e...........................] - ETA: 1s - loss: 0.0051 - binary_accuracy: 1.0000\n 2048/15000 [\u003d\u003d\u003d\u003e..........................] - ETA: 1s - loss: 0.0052 - binary_accuracy: 1.0000\n 2560/15000 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 1s - loss: 0.0050 - binary_accuracy: 1.0000\n 3072/15000 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 1s - loss: 0.0049 - binary_accuracy: 1.0000\n 3584/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 1s - loss: 0.0048 - binary_accuracy: 1.0000\n 4096/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 1s - loss: 0.0054 - binary_accuracy: 0.9998\n 4608/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 0s - loss: 0.0053 - binary_accuracy: 0.9998\n 5632/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 0s - loss: 0.0050 - binary_accuracy: 0.9998\n 6144/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 0s - loss: 0.0050 - binary_accuracy: 0.9998\n 6656/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 0s - loss: 0.0050 - binary_accuracy: 0.9998\n 7168/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e................] - ETA: 0s - loss: 0.0049 - binary_accuracy: 0.9999\n 7680/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 0s - loss: 0.0049 - binary_accuracy: 0.9999\n 8192/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 0s - loss: 0.0050 - binary_accuracy: 0.9999\n 8704/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 0s - loss: 0.0051 - binary_accuracy: 0.9998\n 9216/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 0s - loss: 0.0051 - binary_accuracy: 0.9998\n 9728/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 0s - loss: 0.0052 - binary_accuracy: 0.9998\n10240/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 0s - loss: 0.0051 - binary_accuracy: 0.9998\n11264/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 0s - loss: 0.0051 - binary_accuracy: 0.9998\n11776/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 0s - loss: 0.0052 - binary_accuracy: 0.9998\n12288/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s - loss: 0.0053 - binary_accuracy: 0.9998\n12800/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 0s - loss: 0.0053 - binary_accuracy: 0.9998\n13312/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 0s - loss: 0.0053 - binary_accuracy: 0.9998\n13824/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s - loss: 0.0053 - binary_accuracy: 0.9999\n14336/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 0s - loss: 0.0054 - binary_accuracy: 0.9999\n14848/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s - loss: 0.0053 - binary_accuracy: 0.9999\n15000/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s 143us/step - loss: 0.0053 - binary_accuracy: 0.9999 - val_loss: 0.7189 - val_binary_accuracy: 0.8580\nEpoch 20/20\n\n  512/15000 [\u003e.............................] - ETA: 1s - loss: 0.0068 - binary_accuracy: 1.0000\n 1536/15000 [\u003d\u003d\u003e...........................] - ETA: 1s - loss: 0.0112 - binary_accuracy: 0.9987\n 2048/15000 [\u003d\u003d\u003d\u003e..........................] - ETA: 1s - loss: 0.0117 - binary_accuracy: 0.9990\n 2560/15000 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 1s - loss: 0.0113 - binary_accuracy: 0.9988\n 3072/15000 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 1s - loss: 0.0103 - binary_accuracy: 0.9990\n 3584/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 1s - loss: 0.0094 - binary_accuracy: 0.9992\n 4096/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 1s - loss: 0.0087 - binary_accuracy: 0.9993\n 4608/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 1s - loss: 0.0082 - binary_accuracy: 0.9993\n 5120/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 0s - loss: 0.0077 - binary_accuracy: 0.9994\n 5632/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 0s - loss: 0.0072 - binary_accuracy: 0.9995\n 6144/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 0s - loss: 0.0069 - binary_accuracy: 0.9995\n 6656/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 0s - loss: 0.0067 - binary_accuracy: 0.9995\n 7680/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 0s - loss: 0.0062 - binary_accuracy: 0.9996\n 8192/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 0s - loss: 0.0060 - binary_accuracy: 0.9996\n 9216/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 0s - loss: 0.0060 - binary_accuracy: 0.9996\n10240/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 0s - loss: 0.0059 - binary_accuracy: 0.9996\n10752/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 0s - loss: 0.0058 - binary_accuracy: 0.9996\n11264/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 0s - loss: 0.0057 - binary_accuracy: 0.9996\n12288/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s - loss: 0.0057 - binary_accuracy: 0.9996\n13312/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 0s - loss: 0.0080 - binary_accuracy: 0.9986\n14336/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 0s - loss: 0.0105 - binary_accuracy: 0.9975\n15000/15000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s 138us/step - loss: 0.0103 - binary_accuracy: 0.9975 - val_loss: 0.7101 - val_binary_accuracy: 0.8676\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1522054247430_-762079281",
      "id": "20180326-082332_52076399",
      "dateCreated": "Mar 26, 2018 8:50:47 AM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "import matplotlib.pyplot as plt\n\nhistory_dict \u003d history.history\nloss_values \u003d history_dict[\"loss\"]\nval_loss_values \u003d history_dict[\"val_loss\"]\nepochs \u003d range(1, len(loss_values) + 1)\nplt.plot(epochs, val_loss_values, \"bo\", label\u003d\"validation loss\")\nplt.plot(epochs, loss_values, \"b\", label\u003d\"train loss\")\nplt.xlabel(\"epochs\")\nplt.ylabel(\"loss\")\nplt.plot()",
      "dateUpdated": "Mar 26, 2018 8:50:47 AM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-3082404752090615273.py\", line 282, in \u003cmodule\u003e\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_python-3082404752090615273.py\", line 270, in \u003cmodule\u003e\n    exec(code, _zcUserQueryNameSpace)\n  File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e\nImportError: No module named matplotlib.pyplot\n\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1522054247431_-762464030",
      "id": "20180326-082343_1472628033",
      "dateCreated": "Mar 26, 2018 8:50:47 AM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "from kafka import KafkaProducer\nproducer \u003d KafkaProducer(bootstrap_servers\u003d\u0027kafka:9092\u0027)",
      "user": "anonymous",
      "dateUpdated": "Mar 26, 2018 8:52:05 AM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1522054247432_-764387775",
      "id": "20180326-082357_2121658175",
      "dateCreated": "Mar 26, 2018 8:50:47 AM",
      "dateStarted": "Mar 26, 2018 8:52:05 AM",
      "dateFinished": "Mar 26, 2018 8:52:08 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "user": "anonymous",
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1522054280092_-1247385562",
      "id": "20180326-085120_346297733",
      "dateCreated": "Mar 26, 2018 8:51:20 AM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "keras",
  "id": "keras",
  "angularObjects": {
    "2DBVT14J4:shared_process": [],
    "2DB1XYZSD:shared_process": [],
    "2DAGD6XX8:shared_process": [],
    "2DBKZZRFN:shared_process": [],
    "2D92ZQD39:shared_process": [],
    "2D9P2AZ8H:shared_process": [],
    "2DAYK6KY6:shared_process": [],
    "2DBZJR1SX:shared_process": [],
    "2D8N7XRXW:shared_process": [],
    "2DBBHR3ZJ:shared_process": [],
    "2DA88BSHY:shared_process": [],
    "2D9AE2A5N:shared_process": [],
    "2DB9R62VH:shared_process": [],
    "2DBXE5NM2:shared_process": [],
    "2DBDYNDF3:shared_process": [],
    "2D9MSYR38:shared_process": [],
    "2DA2XEEPC:shared_process": [],
    "2DBG7R9BG:shared_process": [],
    "2DBEX5KX2:shared_process": []
  },
  "config": {},
  "info": {}
}
